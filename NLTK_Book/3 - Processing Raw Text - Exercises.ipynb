{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist # need this to access \"most_common\" method\n",
    "\n",
    "import urllib2\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import re\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Define a string s = 'colorless'. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colourless'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'colorless'\n",
    "s_new = s[0:4]+'u'+s[4:]\n",
    "s_new"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. We can use the slice notation to remove morphological endings on words. For example, 'dogs'[:-1] removes the last character of dogs, leaving dog. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airplane'"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'airplanes'[:-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ???"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. We can specify a \"step\" size for the slice. The following returns every second character within the slice: monty[6:11:2]. It also works in the reverse direction: monty[10:5:-2] Try these for yourself, then experiment with different step values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acegi'"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'abcdefghijklmnopqrstuvwxyz'\n",
    "string[0:10:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zxvtrpnl'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[25:10:-2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. What happens if you ask the interpreter to evaluate monty[::-1]? Explain why this is a reasonable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zyxwvutsrqponmlkjihgfedcba'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!yad doog a si sihT'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'This is a good day!'\n",
    "sentence[::-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Describe the class of strings matched by the following regular expressions.\n",
    "\n",
    "a. [a-zA-Z]+\n",
    "b. [A-Z][a-z]*\n",
    "c. p[aeiou]{,2}t\n",
    "d. \\d+(\\.\\d+)?\n",
    "e. ([^aeiou][aeiou][^aeiou])*\n",
    "f. \\w+|[^\\w\\s]+\n",
    "Test your answers using nltk.re_show()."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a. [a-zA-Z] is a range, + means one or more of previous character\n",
    "b. [A-Z][a-z] means the 1st letter is between A to Z, the 2nd a to z. * means zero or more of previous character\n",
    "c. Start with p, one of aeiou, {,2} means no more than 2 repeats, then the last letter is t\n",
    "d. ???\n",
    "e. \n",
    "f. ???"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "e. wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "[pair for word in wordlist for pair in re.findall(r'([^aeiou][aeiou][^aeiou])*',word)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use from urllib import request and then  request.urlopen('http://nltk.org/').read().decode('utf8') to access the contents of the URL."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Get the url to html format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = urllib2.urlopen(url).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. User BeautifulSoup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html).get_text()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'BBC',\n",
       " u'NEWS',\n",
       " u'|',\n",
       " u'Health',\n",
       " u'|',\n",
       " u'Blondes',\n",
       " u\"'to\",\n",
       " u'die',\n",
       " u'out',\n",
       " u'in']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_1 = open('nltk_chap3_ex.txt', 'w')\n",
    "file_1.write(\"The 1st line of the file. \")\n",
    "file_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_1 = open('nltk_chap3_ex.txt', 'a') # \"a\" means append. This will not overwrite the original content.\n",
    "file_1.write(\"World creates the power of nature, but not intelligence. Nor do we know if aliens really exist.\")\n",
    "file_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 1st line of the file. World creates the power of nature, but not intelligence. Nor do we know if aliens really exist.'"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1 = open('nltk_chap3_ex.txt', 'r')\n",
    "raw = file_1.read()\n",
    "file_1.close()\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '''\n",
    "(?x)\n",
    "'''\n",
    "nltk.regexp_tokenize(pattern, raw)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Rewrite the following loop as a list comprehension:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11. Define a string raw containing a sentence of your own choosing. Now, split raw on some character other than space, such as 's'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N',\n",
       " 't t',\n",
       " '',\n",
       " ' l',\n",
       " 'ng ag',\n",
       " ' this is the ',\n",
       " 'nly place where things are right.']"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = \"Not too long ago this is the only place where things are right.\"\n",
    "raw.split('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not',\n",
       " 'too',\n",
       " 'long',\n",
       " 'ago',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'only',\n",
       " 'place',\n",
       " 'where',\n",
       " 'things',\n",
       " 'are',\n",
       " 'right.']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.split(' ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "12. Write a for loop to print out the characters of a string, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n",
      "a\n",
      "s\n",
      "t\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "raw = 'Last.'\n",
    "for character in raw:\n",
    "    print character"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "14. Create a variable words containing a list of words. Experiment with words.sort() and sorted(words). What is the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ask', 'ninja', 'supernova', 'tesla']"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['ask', 'tesla', 'ninja' ,'supernova']\n",
    "word_list.sort()\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ask', 'ninja', 'supernova', 'tesla']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['ask', 'tesla', 'ninja' ,'supernova']\n",
    "sorted(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ask', 'tesla', 'ninja', 'supernova']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word_list.sort() change the order of original list. Whereas sorted(word_list) does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Explore the difference between strings and integers by typing the following at a Python prompt: \"3\" * 7 and 3 * 7. Try converting between strings and integers using int(\"3\") and str(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print 3 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333333\n"
     ]
    }
   ],
   "source": [
    "print \"3\" * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333333\n"
     ]
    }
   ],
   "source": [
    "print str(3)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print int(\"3\")*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use a text editor to create a file called prog.py containing the single line monty = 'Monty Python'. Next, start up a new session with the Python interpreter, and enter the expression monty at the prompt. You will get an error from the interpreter. Now, try the following (note that you have to leave off the .py part of the filename):\n",
    ">>> from prog import monty\n",
    ">>> monty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"prog.py\",'w') as prog:\n",
    "    prog.write(\"monty = 'Monty Python'\")\n",
    "    \n",
    "prog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prog import monty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What happens when the formatting strings %6s and %-6s are used to display strings that are longer than six characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thisisalongstring'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format('thisisalongstring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the string is longer than assigned length, it shows everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if    '"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format('if')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    if'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:>6}'.format('if')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Read in some text from a corpus, tokenize it, and print the list of all wh-word types that occur. (wh-words in English are used in questions, relative clauses and exclamations: who, which, what, and so on.) Print them in order. Are any words duplicated in this list, because of the presence of case distinctions or punctuation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here let's take the inauguration speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the \"wh-\" words in all the inauguration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'which', 1002),\n",
       " (u'who', 356),\n",
       " (u'when', 162),\n",
       " (u'what', 143),\n",
       " (u'whole', 90),\n",
       " (u'whose', 66),\n",
       " (u'where', 62),\n",
       " (u'whether', 46),\n",
       " (u'while', 45),\n",
       " (u'When', 41),\n",
       " (u'whom', 39),\n",
       " (u'While', 31),\n",
       " (u'whatever', 25),\n",
       " (u'What', 23),\n",
       " (u'wherever', 15),\n",
       " (u'why', 13),\n",
       " (u'whilst', 11),\n",
       " (u'wholly', 9),\n",
       " (u'white', 8),\n",
       " (u'whenever', 8)]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(\n",
    "                                word\n",
    "                                for file_ in inaugural.fileids()\n",
    "                                for word in inaugural.words(file_)\n",
    "                                if re.search('^wh.*', word.lower()) \n",
    ")\n",
    "fd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAE/CAYAAAC+UE+SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXl4XVW1wH8rSZs0TUeGEkppizLXgiTMogIOPCcEEXmC\n4ojvicID9QHPERUfTvhUREUrg6gICNKiIFDmmbTQlrYUSqEDtAVKh3RKM6z3x943Obn3nH2H5A5J\n1u/7znfPPfvsc9YZ19lrrb22qCqGYRiGkQ9V5RbAMAzDGHiY8jAMwzDyxpSHYRiGkTemPAzDMIy8\nMeVhGIZh5I0pD8MwDCNvTHkYhmEYeWPKwzAMw8gbUx6GYRhG3tSUW4BisfPOO+uUKVMKqrtt2zZG\njBhR0WWVIsdgKKsUOQZDWaXIMRjKirGvXJgzZ87rqrpL1hVVdVBOTU1NWigtLS0VX1YpcgyGskqR\nYzCUVYocg6GsGPvKBaBFc3jHmtnKMAzDyBtTHoZhGEbemPIwDMMw8saUh2EYhpE3pjwMwzCMvCma\n8hCRP4jIqyLyTGTZeBG5S0Se97/jImUXichSEVkiIu+NLG8SkQW+7BciIsWS2TAMw8iNYrY8rgZO\nSFt2ITBbVfcGZvv/iMgBwGnAgb7OFSJS7ev8Gvg8sLef0rfZb2zd0cEtT63i/uXbirULwzCMQUHR\nlIeqPgC8kbb4ROAaP38N8OHI8utVtU1VXwSWAoeJSCMwWlUf8/HH10bq9Dtb2jo576/zuHpea7F2\nYRiGMSgQLeIY5iIyBbhNVaf5/xtUdayfF2C9qo4VkcuBx1T1Ol82A7gdeAm4VFXf5ZcfA1ygqh9I\n2N9ZwFkAjY2NTbNmzcpL3rZO5eM3r2VYFVz/kd1i19m6dSv19fVlL6sUOQZDWaXIMRjKKkWOwVBW\njH3lQnNz8xxVbc66Yi49CQudgCnAM5H/G9LK1/vfy4EzIstnAKcAzcDdkeXH4JRRUXqYd3V16Zsu\n+odOvuA2bWvvjF1nMPc+HapllSLHYCirFDkGQ5n1MO/NWm+Kwv++6pe/DEyKrLeHX/ayn09fXhRE\nhIY6l+5rS1tHsXZjGIYx4Cm18pgJnOnnzwRujSw/TURqRWQqzjH+hKquBjaJyBHezPXJSJ2iMHK4\nUx6bTXkYhmEkUrSsuiLyF+CdwM4isgr4NnApcIOIfBZYDpwKoKoLReQGYBHQAZytqp1+U1/ERW6N\nwPlBbi+WzACjfMujdbspD8MwjCSKpjxU9d8Tio5PWP8S4JKY5S3AtH4ULUhDrbU8DMMwsmE9zNNI\n+Tw2t7WXWRLDMIzKxZRHGqmWh5mtDMMwkjHlkcao7mirzixrGoZhDF1MeaTR4/Mws5VhGEYSpjzS\naKgdBsBmM1sZhmEkYsojjZG1Lh9jq0VbGYZhJGLKI42Uz8NaHoZhGMmY8kij22xlLQ/DMIxETHmk\n0dPPw5SHYRhGEqY80rB+HoZhGNkx5ZHGKGt5GIZhZMWURxqploelZDcMw0jGlEcaDRZtZRiGkRVT\nHml0j+exo4OuruIN0WsYhjGQMeWRRnWVUFctqMLWdstvZRiGEYcpjxhGDBPATFeGYRhJmPKIoVt5\nWHJEwzCMWEx5xFBf406L9fUwDMOIx5RHDD0tD1MehmEYcZjyiKHeKw/r62EYhhGPKY8YRtQ45WFm\nK8MwjHhMecQwYpg7LWa2MgzDiMeURwyploeF6hqGYcRjyiOGenOYG4ZhBDHlEUPKbGVD0RqGYcRj\nyiOGejNbGYZhBDHlEYP18zAMwwhjyiOG+lS0lbU8DMMwYjHlEUN3tJW1PAzDMGIx5RGDma0MwzDC\nlEV5iMh5IrJQRJ4Rkb+ISJ2IjBeRu0Tkef87LrL+RSKyVESWiMh7iy1fvbU8DMMwgpRceYjIROAc\noFlVpwHVwGnAhcBsVd0bmO3/IyIH+PIDgROAK0SkupgyjjCfh2EYRpByma1qgBEiUgPUA68AJwLX\n+PJrgA/7+ROB61W1TVVfBJYChxVTuGFVMKxa2NHZRVuHjSZoGIaRTsmVh6q+DPwEWAGsBjaq6p3A\nBFVd7VdbA0zw8xOBlZFNrPLLioaI0FDrxzK31odhGEYGoqql3aHzZfwN+BiwAbgRuAm4XFXHRtZb\nr6rjRORy4DFVvc4vnwHcrqo3xWz7LOAsgMbGxqZZs2YVJOPWrVv5yn1beHVLJ7/6t53ZraGmV1l9\nfX1ivVKVVYocg6GsUuQYDGWVIsdgKCvGvnKhubl5jqo2Z11RVUs6AR8FZkT+fxK4AlgCNPpljcAS\nP38RcFFk/X8BR2bbT1NTkxZKS0uLnvB/D+jkC27TBas2ZJSF6pWqrFLkGAxllSLHYCirFDkGQ1kx\n9pULQIvm8C4vh89jBXCEiNSLiADHA4uBmcCZfp0zgVv9/EzgNBGpFZGpwN7AE8UWcpQ3W9mAUIZh\nGJnUZF+lf1HVx0XkJmAu0AE8BVwJNAA3iMhngeXAqX79hSJyA7DIr3+2qhbdiz2y1gV0WbiuYRhG\nJiVXHgCq+m3g22mL23CtkLj1LwEuKbZcURrqhgGmPAzDMOKwHuYJpKKtbChawzCMTEx5JDCqzofq\nWsvDMAwjA1MeCVg/D8MwjGRMeSTQrTys5WEYhpGBKY8EGurM52EYhpGEKY8ERnW3PNrLLIlhGEbl\nYcojgZHdnQQtMaJhGEY6pjwS6DZbmc/DMAwjA1MeCXSbrbab2cowDCMdUx4JNFg/D8MwjERMeSRg\n/TwMwzCSMeWRwMjh3mG+o5POrtKOeWIYhlHpmPJIoKqqZzTBLTus9WEYhhHFlEcAM10ZhmHEY8oj\nQGpMDxsQyjAMozemPAKkxvSwvh6GYRi9MeURYJSZrQzDMGIx5RHAMusahmHEY8ojQHdHQWt5GIZh\n9MKUR4DuoWit5WEYhtELUx4BRlnLwzAMIxZTHgEabEwPwzCMWEx5BBhpDnPDMIxYTHkE6DZb2YBQ\nhmEYvTDlEaDBxvQwDMOIxZRHAOvnYRiGEY8pjwDdQ9FatJVhGEYvTHkEGFXrcltZy8MwDKM3pjwC\n2FC0hmEY8ZjyCJBKyb55eweqNpqgYRhGClMeAWprqhleXUVHl9LW0VVucQzDMCqGsigPERkrIjeJ\nyLMislhEjhSR8SJyl4g873/HRda/SESWisgSEXlvKWU105VhGEYm5Wp5/By4Q1X3Aw4CFgMXArNV\ndW9gtv+PiBwAnAYcCJwAXCEi1aUS1IaiNQzDyKTkykNExgBvB2YAqOoOVd0AnAhc41e7Bviwnz8R\nuF5V21T1RWApcFip5LW+HoZhGJlIqR3BInIwcCWwCNfqmAOcC7ysqmP9OgKsV9WxInI58JiqXufL\nZgC3q+pNMds+CzgLoLGxsWnWrFkFybh161bq6+sB+Oa961j0ejsXv2Mc03at7VUWqlfsskqRYzCU\nVYocg6GsUuQYDGXF2FcuNDc3z1HV5qwrqmpJJ6AZ6AAO9/9/DnwP2JC23nr/ezlwRmT5DOCUbPtp\namrSQmlpaeme/8xVT+jkC27TOxeuySgL1St2WaXIMRjKKkWOwVBWKXIMhrJi7CsXgBbN4V1eDp/H\nKmCVqj7u/98EHAKsFZFGAP/7qi9/GZgUqb+HX1YSehzmlt/KMAwjRcmVh6quAVaKyL5+0fE4E9ZM\n4Ey/7EzgVj8/EzhNRGpFZCqwN/BEqeQ1h7lhGEYmNWXa75eBP4nIcGAZ8GmcIrtBRD4LLAdOBVDV\nhSJyA07BdABnq2rJcqTbULSGYRiZ5K08fP+LSao6v9CdqurTON9HOscnrH8JcEmh++sL1vIwDMPI\nJCezlYjcJyKjRWQ8MBf4nYhcVlzRKoOUz2OLtTwMwzC6ydXnMUZVNwEnA9eq6uHAu4onVuVgZivD\nMIxMclUeNT4C6lTgtiLKU3F0D0VrZivDMIxuclUeFwP/Apaq6pMishfwfPHEqhwabEwPwzCMDHJ1\nmK9W1empP6q6bKj5PEx5GIZh9JBry+OXOS4bdFi0lWEYRibBloeIHAkcBewiIudHikYDJctsW07M\nYW4YhpFJNrPVcKDBrzcqsnwTcEqxhKokGsxhbhiGkUFQeajq/cD9InK1qi4vkUwVRf2wakRgW3sn\nHZ02mqBhGAbk7jCvFZErgSnROqp6XDGEqiSqqoSG4TW0tnWwZUfJsqIYhmFUNLkqjxuB3wC/B4bc\nG7ShzikPi7gyDMNw5Ko8OlT110WVpIKxiCvDMIze5BqqO0tEvigijSIyPjUVVbIKwsb0MAzD6E2u\nLY/UOBtfiyxTYK/+Facy6Q7X3d7RK+TMMAxjqJKT8lDVqcUWpJLpNlu1mfIwDMOAHJWHiHwybrmq\nXtu/4lQmvXweQ6JrpGEYRphczVaHRubrcIM2zQWGhvKI5reqL7MwhmEYFUCuZqsvR/+LyFjg+qJI\nVIGMqjXlYRiGESXXaKt0tgBDxg9iKUoMwzB6k6vPYxYuugqc1X9/4IZiCVVp2JgehmEYvcnV5/GT\nyHwHsFxVVxVBnook1fKwzLqGYRiOnMxWPkHis7jMuuOAHcUUqtIYZT3MDcMwepGT8hCRU4EngI/i\nxjF/XESGREp2gJG1NpqgYRhGlFzNVl8HDlXVVwFEZBfgbuCmYglWSfTObVVbXmEMwzAqgFyjrapS\nisOzLo+6A55RNo65YRhGL3JtedwhIv8C/uL/fwz4Z3FEqjx6cltZYkTDMAzIPob5m4EJqvo1ETkZ\neJsvehT4U7GFqxRSPo8tOzpR1SxrG4ZhDH6ymZ7+DzdeOap6s6qer6rnA7f4siHB8Joqamuq6OxS\nbDBBwzCM7MpjgqouSF/ol00pikQVSsrvsbXDxjE3DMPIpjzGBspG9KcglU7K77Gt3cxWhmEY2ZRH\ni4h8Pn2hiHwOmNOXHYtItYg8JSK3+f/jReQuEXne/46LrHuRiCwVkSUi8t6+7LdQUr3Mt5ryMAzD\nyBpt9V/ALSJyOj3KohkYDpzUx32fCywGRvv/FwKzVfVSEbnQ/79ARA4ATgMOBHYH7haRfVS1pN6H\nkcN9y8PMVoZhGOGWh6quVdWjgIuBl/x0saoeqaprCt2piOwBvB/4fWTxicA1fv4a4MOR5derapuq\nvggsBQ4rdN+FMspaHoZhGN1IOUJPReQm4H9xubK+qqofEJENqjrWlwuwXlXHisjlwGOqep0vmwHc\nrqoZvdtF5CzgLIDGxsamWbNmFSTf1q1bqa/vPXDHzx/fwAMrtvOFg+p4zz7xrqC4esUqK+W+BntZ\npcgxGMoqRY7BUFaMfeVCc3PzHFVtzrqiqpZ0Aj4AXOHn3wnc5uc3pK233v9eDpwRWT4DOCXbfpqa\nmrRQWlpaMpZ9/Zb5OvmC2/R719+fV71ilZVyX4O9rFLkGAxllSLHYCgrxr5yAWjRHN7lufYw70+O\nBj4kIu/DDWk7WkSuA9aKSKOqrhaRRiCVDuVlYFKk/h5+WUlJjelh0VaGYRhlyE+lqhep6h6qOgXn\nCL9HVc8AZgJn+tXOBG718zOB00SkVkSmAnvjMvyWlJ5+HqY8DMMwytHySOJS4AYR+SywHJf6HVVd\nKCI3AItwA1GdrSWOtALr52EYhhGlrMpDVe8D7vPz64DjE9a7BLikZILFkFIeW9stVNcwDGPIpFXv\nK6nkiNvMbGUYhmHKI1esn4dhGEYPpjxypMfnYWYrwzAMUx45slPDcADWbTPlYRiGYcojRyaOHUFD\nbQ0b27p4rbWt3OIYhmGUFVMeOSIi7LfbKACeXbOpzNIYhmGUF1MeebBfo1ceq1vLLIlhGEZ5MeWR\nB/vt5rLHL7aWh2EYQxxTHnmwf6NXHtbyMAxjiGPKIw/29T6Ppa+20t5pUVeGYQxdTHnkQUNtDRNG\nVtPeqSx7bUu5xTEMwygbpjzyZPIY11nQIq4MwxjKmPLIkyljnfIwv4dhGEMZUx55MnmMGxRq8Wpr\neRiGMXQx5ZEnk8ea2cowDMOUR55MGFlN/fBq1m5q440tO8otjmEYRlkw5ZEnVSLdIbvW+jAMY6hi\nyqMAunuam9PcMIwhiimPAti/O8eVtTwMwxiamPIogFTL49k11vIwDGNoYsqjAFI+j+fWttJhaUoM\nwxiCmPIogDEjhjFx7AjaOrp4ad3WcotjGIZRckx5FEjK72GdBQ3DGIqY8iiQHr+HKQ/DMIYepjwK\nxEYVNAxjKGPKo0BSA0NZxJVhGEMRUx4FMmWnkdTWVPHyhm1s3NZebnEMwzBKiimPAqmuiqQpMae5\nYRhDDFMefWC/7hxXZroyDGNoYcqjD/T4PazlYRjG0MKURx+wBImGYQxVSq48RGSSiNwrIotEZKGI\nnOuXjxeRu0Tkef87LlLnIhFZKiJLROS9pZY5iZTZasmaVjq7tMzSGIZhlI5ytDw6gK+o6gHAEcDZ\nInIAcCEwW1X3Bmb7//iy04ADgROAK0SkugxyZzBu5HB2G13HtvZOVrxhaUoMwxg6lFx5qOpqVZ3r\n51uBxcBE4ETgGr/aNcCH/fyJwPWq2qaqLwJLgcNKK3Uy+1l6dsMwhiCiWj5zi4hMAR4ApgErVHWs\nXy7AelUdKyKXA4+p6nW+bAZwu6reFLO9s4CzABobG5tmzZpVkFxbt26lvr4+p7LrFrRyy7Nb+OgB\nI/nQ1Oqc6/W1rL+3N5TLKkWOwVBWKXIMhrJi7CsXmpub56hqc9YVVbUsE9AAzAFO9v83pJWv97+X\nA2dEls8ATsm2/aamJi2UlpaWnMv+/tQqnXzBbfr5a57Mq15fy0q5r8FeVilyDIaySpFjMJQVY1+5\nALRoDu/wskRbicgw4G/An1T1Zr94rYg0+vJG4FW//GVgUqT6Hn5ZRZAK111s4bqGYQwhyhFtJbjW\nw2JVvSxSNBM408+fCdwaWX6aiNSKyFRgb+CJUsmbjak7j2R4dRUr39jG1nYbGMowjKFBTRn2eTTw\nCWCBiDztl/0PcClwg4h8FlgOnAqgqgtF5AZgES5S62xV7Sy92PEMq65i7wkNLHxlEys2dpRbHMMw\njJJQcuWhqg8BklB8fEKdS4BLiiZUH9lvt9EsfGUTy015GIYxRLAe5v1AalTBF9Zbdl3DMIYGpjz6\ngel7jAVg9ovb+Nw1T/L8WktXYhjG4MaURz9w2NTxXHDCftRVC3cvfpX3/t8DXHDTfNZs3F5u0QzD\nMIpCORzmg5L/fOeb2GfYOu57rZ6/PLGCv7as5NZ5L/OZo6fyH+98U7nFMwzD6Fes5dGPjK2r5nsf\nnsZd57+D971lN7a3d3HFfS/w9h/dS8sr1goxDGPwYMqjCEzdeSRXnN7ELV88isOmjmfD1nZ+8cRG\n1m4yBWIYxuDAlEcReeue4/jrWUdw3H67sqVd+fotC1IpVgzDMAY0pjyKjIjwg5PeQv0w50y/9elX\nyi2SYRhGnzHlUQJ2G1PHpw5yfUG+M2shr7aa+cowjIGNKY8ScdyUEbx9n13YsLWdb/19oZmvDMMY\n0JjyKBEiwv+e/BYaamu4Y+Ea/rFgdblFMgzDKBhTHiVk4tgR/M/79gfgW7cuZN3mtjJLZBiGURim\nPErMvx82iaPfvBNvbNnBt2YuLLc4hmEYBWHKo8SICJeePJ364dX8Y/5q7njGzFeGYQw8THmUgUnj\n67nw3/YD4Bt/f4bWNhtEyjCMgYUpjzJxxuGTOXzqeF7fvIOv37uOeSs3lFskwzCMnDHlUSaqqoSf\nnnoQb961gZdbOzn5149w2V3P0d5prRDDMCofUx5lZI9x9dz25bfxwX3q6VLlF7Of56QrHrbxQAzD\nqHhMeZSZumHVfOqg0fzl80ewx7gRPPPyJt7/y4f43QPL6OyyjoSGYVQmNp5HhXDEXjtxx3+9ne/f\ntojrn1zJJf9czJ2L1nDgmA7WDl9N45g6dh87gl0aaqmqShoC3jAMozSY8qggGmpruPQj03n3ARO4\n4G8LePKl9TwJXD1vbvc6w6qFCaPrGDesk0/LKj540O4Mq7YGpGEYpcWURwVy/P4TuPO8cdw8dxVz\nliynfdgoVm/cxuqN23ljyw5Wrd/GKuD8G+bx438t4TNHT+W0wyYxqm5YuUU3DGOIYMqjQhk/cjif\nO2Yv3lq/nqampu7l23Z0snrjNm68/ynuWtHF0lc3c8k/F/OL2c/z8cP35NNHTy2j1IZhDBVMeQww\nRgyvZq9dGnjX1Hq+dvIh3LvkVa58YBmPv/gGv31gGX94+EWaG2vZ9+WF1NZUUVtTxfCaKmprqhle\nU8Wrq7eybfTrNI6tY/cxIxgxvLrch2QYxgDElMcApqpKOH7/CRy//wSeXrmBKx94gTueWcOjq7bz\n6KqXEuv96snHu+fH1Q+jccwIdh9bh7S1stfaxYyqq2FU3TAaamu659dt7kBVETFnvWEYpjwGDQdP\nGssVpzexfN0W/jx7Lrs0TmRHZxc7OtzU5n+Xv7KWtup6Xtm4jTUbt7N+azvrt7azaPUmt6FlyxL3\n8a0H7uaQPcfRPGUcTZPH8ZaJY6gbZi0XwxiKmPIYZEzeaSTveVM9TU17xZbPmdPW7UPp6lJe39LG\n6g3beWXDNuYuWsq4CY20bu+gdXs7m7d3+PkOnlu9gTe27ODuxWu5e/FawEV+TZs4hsbhO3iucwX7\nTBjFPhMazHFvGEMAUx5DmKoqYddRdew6qo6DJo1l1x2v0NT05th1W1pa2HXqAbQsf4M5y9czZ/l6\nlqxt5akVG3gK+OfSBd3rThw7gn0mNLDPbqPo3LSFFVWraKgdxqi6GhpqaxhdN4yGuhobTdEwBjCm\nPIycEBH23KmePXeq5+RD9gBg0/Z2nlqxgbueXMSWmjEsWdPK0tc28/KGbby8YRv3LnnNVX5qXuw2\nG4YLhz3zJE2TnRnsoD3GmgPfMAYIpjyMghldN4x37LMLDa0NNDUdDEBHZxcr3tjKc2tbWbJmM4te\nXEndqHHdJrBN29vZ3NbBxm3ttG7v4J5nX+WeZ18FoKZKOHD30RwyeRxs3sILupJRtc5hP6quhoY6\n58Bv61Rz3htGmRkwykNETgB+DlQDv1fVS8sskhFDTXUVe+3SwF67NHDCNJgzZxNNTW/NWE9VuePB\nJ9kxemK3GWzx6k3MW7WReas2upXmzU/ez99vj40K27FlI1NWPeOXOfPYaG8uW762ja6X3mB4dSp8\n2f2u397Ja63xQwJv3N7Jxm3tbt3qKksNYxieAaE8RKQa+BXwbmAV8KSIzFTVReWVzCgUEWHXkdU0\nHTyREw+eCMDmtg7mrdzAUyvWs2jZKkaMHk/rdtdC2dzW0T2/adsO2ru0O1IsnQdWLE/e8QOPxi+f\ndXdynVl3ds8Oq5Zu5SPaScPse3spIvdbzbbNm9j12bndy4d75VM7rIrXX93ME60v9CpL9cl56ZXt\nrB+xNlaMZavb2L709YxtDq+pYt22TtZs3B5br9CyjW1dtG5v796PtfSMKANCeQCHAUtVdRmAiFwP\nnAiY8hhENNTWcPSbd+boN+/MnDGbaGo6KHa9OXPmMO2gg3tFg7W2OcXyzLNL2Wm3id0KZ1Mqcqyt\ng3XrNzJ8xMhI+HInOzq62LJ9B8OGxT8KO3a0o1LtQp07u2jvVNo7O9myoxOAN7ZtTT6gVwJDDC98\nNrns4ZbksoceTy67bXb/l83sUZzdyrG6is6ODmpuz1S4He3tscuzlnW0M/Kue3op4VTH1i2bNzF2\n/hOx9TZu3MSYQVrWl+1dPGEjb9ljTGx5fyEDIeJFRE4BTlDVz/n/nwAOV9Uvpa13FnAWQGNjY9Os\nWbMK2t/WrVupr6+v6LJKkWMwlOVaR1Xp6IL2LqW9U9m0ZRs1tXVOoXThf5X2Tti8bTtVNcPd8i6l\no1PZ0QUdncrWth1QPSyyfk/9HR2dVFfHBw20d3TQRXXvOn6+qyvZBxTyDyWVKU6eDnUyd1T+a8KI\n8I1jxvHW3WoLqtvc3DxHVZuzrTdQWh45oapXAlcCNDc3azQnVD7MmTOHpLqVUlYpcgyGskqRo5LL\nurqUHZ09nU3nzZ/H9OnTM+rMnz8/dnm2snnz5rPfAdNoi7QIU51bn33uOd785vgQ8qVLlw7asr5s\n78PvaGLnhsKUR64MFOXxMjAp8n8Pv8wwjBJQVSXUVVV3ZxQYV1fNrqPqMtZLWp6tbPyIaiaNj2/9\njWxdQdN+E2LLxmxZNWjL+rK9YisOGDgjCT4J7C0iU0VkOHAaMLPMMhmGYQxZBkTLQ1U7RORLwL9w\nobp/UNWFZRbLMAxjyDIglAeAqv4T+Ge55TAMwzAGjtnKMAzDqCBMeRiGYRh5Y8rDMAzDyBtTHoZh\nGEbeDIge5oUgIq8BgSRHQXYGXq/wskqRYzCUVYocg6GsUuQYDGXF2FcuTFbVXbKupao2pU1AS6WX\nVYocg6GsUuQYDGWVIsdgKCvGvvpzMrOVYRiGkTemPAzDMIy8MeURz5UDoKxS5BgMZZUix2AoqxQ5\nBkNZMfbVbwxah7lhGIZRPKzlYRiGYeSNKQ/DMAwjb0x5GIZhGHljymMQII5J2dcsLyKSMUJN3LJy\nIiJVInJUueUwys9Aea7KhSkPj4gcJSIfF5FPpqYc61WLyO4ismdq8suPjlk3Y1nCNieLyLv8/AgR\nGRUqUxf1UJR09SIyXUQ+JCInRyYRkTNE5Ft+nT1F5DB/Lv4U2Nyjcct8vWcDMsQP6u3KpiYtE5Gb\nReT9IpLzfa6qXcCvcl0/Qab6tP/DROQcEbnJT18WkWGR8on+/nt7ZKoWkfMC+5gdtyyHcxl7TrLV\nS1u3SkRGR+rFXvOkYxCRQ7JM1SJyb8I2Y++9tHVGR58Zv+yjqWUi8g1/Hq5OlcXtK+m5SnsWMqak\nbXoZEo8tbd30e6haRH4SWH9k6pqKyD7+mR2WtH6/UIqeiJU+AX8EHgGuAH7pp1/4sj2AW4DXgFeB\nvwF7+LIv49IALAQW+Gm+L5sbs5+5/ncfYDbwjP8/HfiGn/88buTEF/z/vYHZOZRdAxyacHwTgBnA\n7f7/AcBn/fzRwF3Ac8Ay4EVgmS/7A9Dit32Vn/4A/Br3gl3s1xsHPOnnHwKGp+1/N6AJWAy8FTjE\nT+8EnvUHdwH6AAAgAElEQVTr3ArsmSD/MuDHwAFJ5zRt2Rz/+y7gT8ALwKXAvjmek58AH8FHI6Zt\nO3TtjgIWASv8/4P8PfV7fw6P89NVwO/9Oj8EXsK9pGb5aaYveyJm/3XAeGCeP+/j/TQlx3MZOieh\nen8GRgMj/TGuAr6WdM0j9eKO4V4/PQq0+3tsjp9/1K8zGxgTUzd07x2KewZfwqUmmgc0+bLUc/k2\n4D7g/cBWQOLuocj+Mp4rep6FfwDrce+EvwFvALfl8PzHHlvoHvLzjwXknAPUAxP98d8I/CmX91+h\nU9lf3JUw4V5qGS8KX3YX8GncwFk1wKeAu3zZUmCntPWPBL4CrATOj0zfAeb5de4HDgOeitRLvYye\nBoanlS3IoexZoAP3UphPb0V2O3BqZP81afX+DdgV2Ck1+bJFCeck9RBE5Uht+1qcgvtm5Nj/jHtZ\ntNLz4rgXN5Twyb7eA758tl8+k56X6Cic4nwEeAw4C6eMPuKP9+TI9ClgYZq8Y4D/8NfkEX897wic\nk1agC/cy2+T/b8rh2j0OTEovS+0jTabUfpcAtQnn+WfA5cAx9CjcH+MUfBs9yv5F3IvyS9nOZZZz\n8mDgGjztf08HfgoMo+f+irvm5weO4RBfdjPwlohM04Cb/PytwAqcgv9FZArde/OBYyLL3xaR8Sn/\n+7/Ax/38WmAD7rnpvs5p1zv0XN0JNEb214h7if/Sbzsq99V4RZp0bKF7yP/+2l+TTxC559OeyS8D\n/x29ZsWaBsxIgkXmGdzX8eqYsl1U9arI/6tF5L/8/EpgY9r6w4EG3Mso2nTeBJzi5+tV9QkRidbr\n8L9tqrojVSYiNYDmUPbewPHtrKo3iMhF0D2sb6cv26iqtyfUe1REDlDVRWnL270pSb0cu+BetuAe\nshdwJtHU8S9R1Y+LyEdU9W8J+/pmkvCq2gr8DvidiLwDp4x2wn39jgc+GFm9Fado8LLtBJyBe+Ce\nwn11vw04SlVPiDsnqtrL5JFG6NqhqivTyjqBThF5k6q+4GXayy8HpwCG4ZRBOgf73+/2Ph06VUS+\nrKq/TJAx8Vz6/SedkwbgAwnVhnkzyIeBy1W1XURS917cNQ8eA64Ftq+qLogc2DMisr//e7Of0jk8\ncO91quqDke09JCKpa/OyiPwWeDfwQ3G+tjWqepCI3KqqJyYcd+i5mqSq0XfGWlxLqAX4EE6RpGgF\nUia8pGNLyR13D4Frda7Dnbvu1f22RESOxCn3z/qyRHNvfzCklYeIzMKd/FHAIhF5gshDrKofAtaJ\nyBnAX/zif8ddQHAP/n0i8o+0eheLyNWqmpTV93UReRM9D8Ap9Ciu+0Xkf4ARIvJu4Is4U0awTFWX\ni8jbgL1V9Sr/UDX4elv8CyO1vyPoUXr3isiPcTdg9Bjm4r4oHxWRNb5M/DZ+iDPl7Soil+CU4jdS\nx+73Ua+qW6MHrap/E5H3AwfiHoTU8u+q6v0iMtnLf7e3+Vb7bVXjzAyfxplnfop74R0DXKaqn447\nySJyC7Avziz5wciD/lcR+VTSORH35J4OTFXV74lzmjaq6hNZrt1Kcc529S/ac3Gt2t/587zMn8PJ\n/ljAmU6eFufDiJ7/c1T12Ljj8qwR5+9qFZFv4L7ov6+qc7Ocy9A5acGZPDLqAb/1ZfOAB/z2N3lZ\nQ9c8dAzzReT3wHX+/+m4r3tU9RoRGYEzoy1JVfDKIP3eSynL+72C+Avu+nwM93weAvwA94H4E1Xd\nICKNwNf8vk4UkQk4sxfA46r6mi8LPVezReRf9LwbPgb8w8v+Z1VtjzvopGPzJN1DJN3nnv8CLgJu\nUdWF/gPl3sD6faeYzZpKn4B3hCa/zmRcUzHl8/g73i4MfDtu8mW74EwM/wTuSU2+bC/gbtyL42Wc\nzXiKL6vCfTnfCNzk5yWHsm/jFMlz/v/uwMN+/hDgYdzL8WGcf2O6L7s3ZkrJuRT3BTXVn4fJuHTN\nAPsBZwNfAvaPnNMjSbbZ/gankFZ6eRcAM3xZyJ+zDNfEPyrmGs7B2eKH4cwtrwFn+LJjA9c+7pwc\npD3mgSS7euja7YxTamtx98p19JgAa3H+kelEzFTAmXGTLwv5ZeJs+I/ncC5D5ySxXsL6NTlc89Ax\n1OG+xm/x03lAnS/7IM6k96L/fzA9JrSkey/uXk6/p3cF9kxNftlHcT6Sa3D354vAKdmeK///JJxp\n7mfASZHle+Oe0UW4+3cZPb7E0LGF7qFEf1tZ3p/l2nElTbiXY13k/wj8CyHH+vUxy+7ENR8X45TR\nH4Afpq0zEhgV2O54el7y1QQcYDh/iNDbVjo/Ml+D++KfBgzL8bgejZEncfLrhGy289N+G4AHI/In\n+XMaQsftf0/CvaTG4L6QT06a/Pq16ecE/1InYFdPunb++pwXkPMo4OPAJ1NTDuc/5KuKs+GnliWe\ny5AsWa5BSAmErnniMWQ59jn+Wqb7j/4Ys27Gsph1PgQ8D2zBKYdOvG8M15raNbLuLhF5sz1Xk4F3\npd4DqXsC91FxPK4lNRnn8/xu6NhyOIY4f9smIv6p9CmX57zQaUibrSLciHugUnT6ZYf6ZurnceaS\n7vOlqp/xNsYZuJfgniJyEPAFVf0i7mthhoicq6r345rUK0RkbfrOU/ZNVb1MRO7D3eg1uJvsVRF5\nRFXPExemO1xVd8Qcww5V1ZQdWkRGAqPFhw6msY+IoKo3++b6D4DdVfXfROQA4EhVnQE8JSJ/xn15\nteG+yBXYFtmW0mPO2ssfR5LNNlVvq4jsjjP/NfplIX/OCBE5h5hrgHvpg/vyvlFVN4oLI436QaIo\nzkT3qKoegouUS+1zLq5FkujTEZGxuBfuFKAmcu3OEZGP475AeyEifwTehHsRpc7FCcC1IrIgcpw9\nQqpOJ+yrirPhp8JvE89lgiyK++IOXYOrcRFGX/f/nwP+irv/Q9c88RjEha5/B/dyjV7XvYB2fy2j\n2+zCKfvoua3G+wBE5Pz08+i3dxnwPeAI4G5VfauIHIvz+wBUqeqrkSrr6DmXcc9Vat+fxwVvjMed\n04m41vXxwAhVnS0ios58/R0RmQN8K3BsiMg1wLmqusH/Hwf81N/rcf62tTgzbskx5eGoib6Q/QM0\n3P+9FReFcjc9D0SK/8M51Gb6evNE5O2+LGXvXO3t/K/glEzIGQsuhG+TiHwOuFZVvy0i833ZMuBh\nEZmJ+4JKyXsZcIN/mYz1N/VngDVkf4leTfJLYQROabzHl/3T7U4/E5A/0WYL3OZfvj8G5noZfu/L\n7pdkX0/oGswS1z9hG/Cf/kX/vCb7QXYTkSa/n7fiFB8401cqtv4XJPh0/Dl4DGdy66I3D4nI5bjz\ntyWyvBkXZtytJLzNHZId1BD2VZ2KU0AZNnzC5zJDlgiheiFFFrrmoWOYgTNVzSHzui70yrhaRPbG\nmZT2A6pEZBM9120H8ISfDz1b7aq6TlwflSpVvVdE/s+X3RHju0gFkcQ9V7/zZWfjWgKP+3PyvIjs\n6svaxPW7eF5EvoQzcaZ8JenHdg4u4g2cpWFDSmhVXe/vU4j3ty31H6cE/CjFoZjNmoEy4cJxPxT5\nfyI9NuLEcDd6bMxxYYMfwDVNp+FsrnOi+whscwHua/xOfHw5PWaeb8dNkbrvxr2YfwK8O8djfzLm\nGGKPGdjP/x4SN/myRJtt2rZqicS6E/bnBEMOcV9+1X6+3p+X8xOmrGHDqWMl3q4e6hNwb8x0jz+m\nxkC9qOljBD2mjyYy/TJvI7vpMHQuE2XJUu8+XIRbyqR3BHB/tmuecAwpU+zjgXNSD1yC88G0+Pk6\n4H8LfMbvxr28L8cpiZ8Dj0TKTwYu89NJaXVTz9WPiTxXpD3/uI/x1LN6qN/fHriPs78BR4SOLfX+\nAMal3dsp02Gcv22yL0v0oxRrspTsgNfmf8I5wwTn0P2kqi4Vke/jbrK4nqY34W62y4HDcV9czap6\nWpb97YGLBU/1OH8Q11RdJa5n6jdxTrn/9FETP1bVj0TqZ0S1JOznDFW9LtSc92ayj+D6rhzivwx/\nqKrviJFzM/B2XKROzOb0OBHZRX2kSoJMR5FpfrrWm9f+oaoZIatx1yDBHJfiVHq+fOMEvVgCYcMi\n8gvgelV9JKbsPNx5uI3e0VFvxKwbjeY7GPeF3CuaL2r6UNU3+S/R36jq8X4bNbjoKMG9HJ6jx1QY\nc2i6V9y5zFGW0DU4BHcvTMP5HnYBPqqutZ3tmvc6BvVRSCJyKc5XFBfpl76N/VT1WS9H3IHPlbCJ\neSSudVqFi+oag/MhrvPbn0xalJm6EHFEZDdcC0NxH1tr/PIf4fqJfBLXv+KLuL5RqVZ8zs9qZP1P\nAv+DU+CCa/Veoqp/FJFqVe30x1KVks/Xm4Mz392nqm/1yxao6lty3Xe+mPKIICINAKq6WURa6bH3\nNuBu7lTMuKrqaBHZGfcF8y7chb4TpwTWZbmR78J9AadewmcAp6vqu7PI1+1jUdVePhb/4P8QF00i\nfqpR1REi8u247fmXaNxL4RRVnV+InCLyHM5h/VfgbxppgkuCvV2dv+Aq3M3/gK97B673btI1qMUp\n/IRDizetRRTqVyLbjla8TETOxJku9sWZr65X1RZf/2zcl+KGSP3USzvdf3SpP97f0mPGjO7rfhF5\nGm/6SH/ovbnyeuCv6vuI5ELCufwyzj80NyBLRj1V7fDbrMVds6giq1LVtizXPPEYJD5NR+ojZB/g\nq/Q8P/v6fSYpzeNE5BHch1gvM1jqIyFJQYQUuDjz8bdwLUjBBb98V1X/4M1Sn8WZdQX4Fy5zgGZ5\nVtOPLSVnyndzIJAKcb5HfT8rEVmBu5Z/9cujZtDHVPUIEXkqch/NV+c7Kw7FbNZU+kRPSGesicOX\nXYe7sfbPc9uP4F7mp+K+7D8CfMSXZZhh6IkaSqVDeZXMdCihqJal+coY2UZsJFYWOROjh3Avw8tw\nPprbIuc5sSe/Lx+GCxb4Ey50MpXCo9BrEHcuL/BlQROgX2c87gNgNs6Pgj+mnRP2lx5Z9FOc72M9\nLlLmBzhz5vhInZDpYzLw37iX4ZO4F86xvizRdJhwLuf7ezJRlizXIDHdRpZrHncMsSlQ0rY9D/hP\nv92m1JSlTsjEHApfDkWZLSFidsWZ7pbkIH/oWQ0eG641tjuZIcX1/v66GaesLwfe5stm4J7H+f7Y\nfolTgEV7fw51h3kqciLkaJuB64z2C2/emosLL/15qHWBi4y4IGGboY6HV+G+9lOJ1c7wy97tt50U\n1bJWVWNNNVnkBHcTp8oOEReJdW2SnEktCFzEDuo60z0hIj/AvVCuwSmAUE9+1PVavt1vawSuN/Pn\niL8G21T1EyGTHPHn8nScWe7iuHppvBnn+5hMjxlsKc7mHEe6U/krInI87vw24xTup4ErRWSDqh5A\nlo6fwI+AH/mv4W/6/1XER9goPvIo5ly+XVV3FhcIkiRLXL2TROTXhAMMEq956BiyXLsOVf11XHmS\n6RMXkPE+jTExk8W5rclRZutw/rEUrX5ZXLSY4Fuhfh9Jz2ro2L6M+5BZ69dPRTJOV2f+ugHnxB+H\ns3rcj1M2X8YFvbTh7vl/Ad+P20d/MaSVh6r+1v8mvkjURWU8gHOAHYvLBzQNd+FCUUChG/kzuC+D\nn+FujFRuIciSDkUyo1pavcmqRUT+iuvEGLUf3xySM4siSJLzXyRE7IgLkz0JOM1v9xZ6IsQSe/KL\nyL/hTEXvxDlnf4/7ykq6BqlU7iHFn3gus5gVf+SP4QWcyeV72mOK2YLrEX5v2jGcQ3Jk0Qjcy3aM\nn17BBUYAXIgzfSwAvoCL5kpFoKVMLR/zUyc9vaITe26HzmVIloR6s3ABGHvglEKKVpxtPumad2e6\njTmGlK8p7tqNEJHxuCi6L/ptRX0wPyfzfv2CuCg3gP8RkQwTM2EFkajAcR8Lj4vIrX79E3E9488H\nLsDlUouLFot7Vl8IHZs6v9m5uLQt64hBXHqej+Ei7VroeUa2Al8XkUs0Dx9LXzCfB1lfJLNxLZRH\ncS/gh9THhIvI06p6cNq2svpKssgyG/fFHP3a/7Q6+2ucj6WK+LxIqf19Jk7OyP4Wkxy6mSTjjcA5\n2juvT6rsRZwCu0FVH/XLziO7vf0vOFvu7ZrmsA1dgyxyhs5lon1cRL6As92/HrPNM+P2pS7lRLr/\n6EBch7S1uC/ex3CZUdf7bVXjwrFPT5D/cdx5uxHnM1iWVp4UfJBxLkXkSi9Pa5wsfp3QNQgFGGRc\n81yOQUTqVHV7zLYSAwJw93rSh8t1OH/Ng+mtcAk4t7P4LmL9hZ7Pq+oecQUJz+ox9LQmMo5Nnd/s\nXlxEV0f6CiLyEi4X2Q24SKotkbKjcMo+w8cSkL9PmPIAsrxIfoazSbbhQg0fwHUw2ybhSKzQjRxS\nVpNxL6Aj6fnaP0dVV2Q5hqNV9eG4ZVnkDCmCdDnf5YteIDliR/xD1x1lIm4cgqOA/XE22Yf9cT2i\nkSgl6e3QHIFz+LdmuQYFncssCrUKZz/eS1W/K26Mlt28aQZv+tnHr94dPeTLopFFP8XZyJ/x+34U\nZ/eOOjofAo7TmI6fIrKvJsTsJ7UYfQso7lzOxKVZSZQlod7pqvp7CQcYZFzzHI9hKU6xPkjPR0Eq\nv1icYqnDBW8k3a/H4l7Qx/hzEzUxxyoI3MdXogJP234V7uW8yf/POVos/Tjijk1Vt4vIDNz9k54v\n7zIRGZ3ad8w2H8dFZs3UHof5M6o6LdtxFYopD+JbEDHrjMI1Ub+Kc2Kl7KBJkVihGzkYFRKQIfSi\nnKuux3R0/U56Oquly1mHc/CGQjfT5fwA7mG5luQWRCjKJGpvP9JPG1T1AMkSsuqPJ3oNdlPV2j6c\ny5BC/TWuA+Bxqrq/OPvynap6qIi8E2fPfwn3EpqEy0X1gK+b0RrAXfuj/DQNN+7Do+o6gF6LU6oZ\nHT8l0Ps/1GJMOpc45X9gQJa4ejP9OQhF7IWueSiDAV4xH4MLB38f7n44OP1+FhdqfAzuyzv2fvXr\nVdPbvLnNH3OohRdS4H/22+nEOdxHAz9X1R9LOFos32d1rrpQ+dB53geX5WGCqk4Tkem4vmPfF5HH\nVfVw6R1tNU9VD4rbXn8wpH0eERL9E+J6hx6D+/J9CZej6kFVvSfUutCwryTRmR666Yj3Xezjvwp3\nkd4OyNG4L8uD4uSULKYkTy85/UviKJwJIqkFEep1H7L9Jzo0k65BnIxREs7lJ+hJk5JkHz/cP8hP\n+YXrpSfjwE+B96S+pv0D/RegKdAauFZENuD8HxtxSvgwnGM0lM78apJ7/4eCD2LPpVc0zwRkiavX\n4edDAQaha554DOL6ER2Nu7YH4VLFPC3xGQCW4/pSXULC/SqZ5s1DtcfEHErtE8rccIC6jA+n4z62\nLsR9qPxYwxmD457VsQnH1h18oIEMxbie7V/DhX6jLpz+zzjHeKiXf1EY0spDevsnkl4kdThH4RzN\ntEOGIrESb2TCzvSQEz7jRSnOgfZOwuOHxMk53h/bRSQrgl5yqupX/T6zReykR5k0isjD9NjbH8Gl\nUl8fWSfk0Axdg3zP5T/UmSMTFT/h8UqGRc0wqvqc9Az32Sv1h7h8XEeJi89v98f9CE75LfD1Qy+L\nuJQge0qW4IOEczleRK7HXbNYWRLqRc9BYsRezDXPmtsKNyDSk8APVPU//H7OJN5BPwnXSgp9uMzH\nfWBMwynGDSLyqKpuI6wgQgo8cRyTLK2quGc16dg20RN8EMqXFxpL5j9wH6YTcb3P78R9DBSNIa08\n1A/6k6UFkThucJbWRdyNnIrYgGRlFQrxzXhRak/SxavVjT0QN6ZCnJzbVHW/BEUwgZ4HLENO3IOc\n1IKI+wLagYuOeh53Y6/COS+j3C/JIasZ1yBHxR86l4mKn3BuqxbpPQbFGbioF8hsDUzBvezO0xgb\nvT+O0MsiLnrrNVxailCLMe5crsomS0K9XPKLFZrb6q24dCsfF5ELcffH/ap6rCQ46EMfLqp6nl8n\nZd68Cnc9agkoiCwKPHEcE8Itw7hn9RrgmqRj84RacYljyagL7sjqt+lPzOdB2NGWpV7WKCCJt9OH\nnOlxqThy6e0esjuHIsbG4HwPR/vfsbgOUp9Ol1Nyi9iJizI5B9c5LWRvT4x4yXIN8jqXaeUZ9nFV\n3c+X7YfLjiq4zmQpc18t7ovubX4zD/pj7STgPwrIn+jolPje/4/iOoElBh/04VyGoo5CAQbRa17l\n66UyLSRmMPB1G/y5PAaniEeq648S66DH3eNJ92u6efNBvIk5ImucUz/x2Uk43hrfgnpSnR8s6mcI\n+RlTz+puOPNbnC8r0XchLlXRlbjnZz0uku90/9GYrS9Xv2PKwxN6kQTqhKKAEm/kBGX1AdwXOiTf\ndKEXZeglFCfn6bgOcCFFkC5nvZfxHpKjhxKjvvx8ys59lD/m1LjpOUW8pNOHcxlU/P5+mEDvB7FX\nxJu4mP09cEomGIockD/0sgilBEkMPvDbSIwIK4RsijhL3aTcVi24VkEq6OFB4ARV/a1kOo4/iEu9\ns4jk+/WrfhsZ5s0sH1dxz85KVZ0kheeFCz2rt+NbLP461+B6or9FcsiXJ/G5rQoKHOkTWsTu6wNl\nwqWfeAzXGe5kIgPD5Fh/FC52fDnObgyupXE4frS1mDrVuMykF/l6z/rliak4cIrtW7gswMtwmU/P\n9WWJGX4T5OzCmVuu9vt7C2SmDomTE/cVeZav24JrXVzs149LY7ES19luBc508EdceoaDcA8BOFPM\n8AKvXyHn8me4h/suXC/h43BjMODP0es4B+58nEkulTLkPpzJbjzuy+9xfw6ypv5IkP0mnAKYi1NA\nX8Xl0ko6l6mstmNwHcW+hzMltQBX+bJ3+vNwvz/GF3E9zLPJcrQ/H8/5++tFf59s8lMXLtig1U+b\nfL1QSp1huJbnTX76Ej4FDq4TZ67X+A5yuF8D9UPpQuKenZX+99txky8LjUYZelYTM1kTzlA8BqdY\nWvz0U3xmarJkni7GNKR9HhFCjrZEYloX3VFAGvCVxHz1Rp3pibZ4DftYEu3OATnvpceU9BVgmohE\nTUmh6JX0iJ0jxY2zEBf1VUd2e3vIoZlIH85lyD4e6uUbO96KqjaH7PGBQ4hzdF4syVE5e0n24IPE\niLDQuSRhfA115qdQgMFVJKfU+TVOgVzhyz4BPCgiN3jZMoRQ91WfboZ5xU+XkXC/Zjk2NNmpH/fs\nPOzrhKLMFuISJfZqGfp6oWc10Q+kYd/FH3Cmv1S2gE/gzvPJhANHioIpDyDLiyREKAooRKKyCt10\nWV6UoWiLkJyh0M10OY/19trDyYzYGYd7kOKivo5S1eeznJNQxEuIQs9lKPx3JT1O3XRqxA28dCo9\njtIUoVDkWOJeFuKicj5FfEqQF8kefBCKCAuxUVVvTygLBRiEUuocqr37GtwjImvIfo1jHfSqGrpf\nQ4Sc+onPThZfQuJolFme1fNxDvE3+Q+BXfCRkVn29yaNDM2A+8jo9B9tkBw4UhTM50Hsl3mGo61I\n+41zpoec24k+lgL2fQ49zuuoIngE54DsiqybkvMS3Atyz6QWhIhMVpcMryDiHJo51sv3XIbs46Fe\nvnHjrdyNi3pJ9B8F5A51JkuKOBLCwQd/wJmYohFhVZrFeSpZekwn+QUlnAZmLm7cjxf8NvbCmXAO\nxfUUzxi216/Xy0Gfz/2asL3E4ROy1IvzJYzF9eW5DpeJINoy/I0/J8FnNeAHCmW7eBT4mqo+5Nc9\nGjeS5JFZWoZFwZQH4RdJkfYXcqZnVRAJL8q8oi1E5DK//UcCiiBvperl+G/cy60uIsdxSXV8vbwi\nXnKRsVBlG+OsTR1DrAlDRO7A2aqDqT8S6mYbg+L9ZJ7L7/qyjOADVR0r8RFhV2jMIE9psoR6TIcU\ncTQNDLhznUoDczxOsSzDvSgn4xTLvSLyhKoeRgyS5qDP5X4tlCwKPC5/Xapl2ExPmDa4j4er1SUj\nTa2b8az65Ul5yUJRbQfjshuMwZ3LN4BPqQvnLShitC+Y8igDuSirBAURelH2e7RFIUpVRO7Exbp/\nFfd1eibwmib3t0jVKyg3T6HnMsdjiQvrjE0RgWuVJbYGAvsIvSx+g4twOxaXh+kU3CiGy8nxC1x8\nRJj60NhC6Uur1yuzff3fJdqTrPFnOH9IdMz3B+m5f/NOLBqQIaQgQl/7oTQ2oWSRoWc1MS9ZaH+R\nbY/2FTalLc87YrQvmPKoMLLcdCFTS9b8XKVAROaoapNERjETHw+fpV6/5+Yp1BwZagWJyP34FBFx\nSi6pNRDYV+jlNF9Vp0d+G3DRbucSbjHeh1NoNbgX4qt+/fOyHHcwD5VfJ+6j5ke4FBnbcFFR03HB\nEdf5Oklf2aGWTr+aYbIoiHyzY6dG6Awliww9qxl5ybLsT9WFl5+La8W14lKVHAJcqKp3hlqGxcIc\n5pVHonNbAxFclCHaIoFUf4LV3uTyCi6sNRvFyM1TaEBDqJdvXIqIsZI99UcvJLce8qmv+q0isjtu\nEKLtObQmYyPCcjjuq0nOQxUKMHiPqv63iJzky07GvfivS/rK9nKFckOFHPSFkG/mhsTsE+JS9oN7\nyceS5VnNyEsW2l+Ez6hLffReXN+oT+DC3u+kwIjRvmDKo8LIctNlkONLqJR8X1yv9a/g7OCjceGf\n2ej33Dz5nsu0uklhnXEpItrJHoqcvv1cXha3ichY4Me4l6cSGSgqQCgiLEQoD1VIEaciud4P3Kiq\nGyPnrle+LwBxo1MigQ54Gg51LYQMBZHjsxOrxPwKoTDeDMRlBlbCeclCSjN1Ut+HU74LxZ9oLTxi\ntGBMeQxwcnwJlVKe2/zsRtxDn2u9kufmCRBqBZ2NSxGxn4i8jAudPVZVXypwX6G+KN/z6/xNRG4D\n6tSPd5GFi3EpQh5S1SfFRThlC5WGcP+DkCKeJSLP4lpK/+n9C6nxKuKy/2Yd/jnGDBMNdc2ZXBRE\n6O7I3RoAAAhWSURBVNkJKbGQHyVBnHvIksk6i9Kc432KU4GLvKLo8scZahkWBfN5DBKkDNEWCXIU\nlGOn0HrFQHII65SYFBF92F8ox1bSeN2h7QVTxATqBfNQBerV4l70G1W105+bVLhv3vm+/Db7LSzd\nby+ULiQ09k4oyiyvIBXJYVC0LPurwp3LZaq6wSv6iepSs5c0YhRMeQwqSh1tkSBDoYMzlT43Tx4k\nmVhSaJae8IHthl4WiVE5WbaZONhQDvLE9j8oYH+rcNmJQ0MPZ/1giHPQZ5MnQcbgx1XSsxNSYnGO\n9hxlCQ2Klq1/yHQyz9fNlAEzWw0S+quZ3w+EHJPFqNfvJLzUDsb1eu5vQo7ODH9BCOkZrCsuRUx1\njvIcRs9xHyIiiS0dcdkGJhKfRmUEbgyM0HgxiWne+9sMk8X8lPjsZPElFBqkkpiJILQ/cZ0/p+N6\ntKdCshXXyis5pjwGDyWPtkig0AeqUqLFIDCIVH/vKMvLKTRaYBzDcRFAoYHBEglFRiVUeS/JaVQ+\nr6o3SzjfV+iDodBIuViyfFwlPjsJSuwCKSAliGQOaZCRlyyL0jxCw3nSSoqZrQYZ/dXML2C/WePU\n+7NeMQmZI8T14/glri8HuAf7XFVdVeC+4vqivBeX1bdQf8FkLSBFjATGRc9SL9RZLjReTMFp3vMl\nFx9K3LMT8iXkG6QiOWQiyLK/GcBPVXVRnodfFEx5DBISXkJFz88VI0dBUV+VEi3mZQl13LsLl0H2\nj37RGbgBed5d4L4yXhaSZXx5DYwP4usXmiLmRlxakbzTf0hmGpUP4V7UGfm+yvnBkKAgCu1MmneQ\nikg4L1mW/b0D1/doDe6cCe58TQ8fdXEw5TFIKEe0RYIchY7KWPZosVxeanGtkkIdpwE5skblZKmf\nV4oY6d3/oJCWTlwalXG4l1zoK7tkHwwhBdGXZ6fQIBXJMxOBr7MUl5F3AT0+DwppZfYHpjyMfqcP\nD1TZo8W8HKGwzsQMskWQIzhaYKBeXili+qGlE5dG5Xbg7YSz/5bsg6EYH1ehSLmE9fuaGfhRVT0y\ntE4pMYe50a8UGvVVQdFiEO7l+xmcz+NnuK/1R3CO4GKQ9/ggnnxTxEzEvdBCkVEh4tKoNPpWRuL4\nG6EIqBz2mRfah2wDAfINUplCnpkI0nhKRP4MzKJ3y7As0VbW8jD6lVwck/1Zr1iUsxUUE5WT8/gg\nvv4HcAp4Ej0pYi5W1ZlZ6hXa0vmm38/xwK9wSnUebpCqxK/sfL/cK5VSBamIyFUxi1XL0JEWTHkY\nRaLQB6pc0WJpMoQ67hW9J3wuUTnFIBQZlcc2anFO82+TfbyYivpgyJdKCVIpF6Y8jH6lD5ErFfMg\nhl5qUqKe8H2Mysl3YLA+tXT8NvJOoxKpW/YPhkIodZBKf4eJ9xXzeRj9TaGdu/q1U1hf0HDHvZL0\nhM/mL8hSPbHndgJ7kn1c9EQK6FyYqlfyZH79SZH8KCGuwoWJf9T/P8MvKyhMvK9Yy8Mw0sgS1ln0\njm39EJWTd+hwH1s6hXYurIjw8oFCKcLE88FaHoaRSUYrSERaRaRU46ZMoW9ROXmneuljSyffNCqp\nfZb6y32gs07cWCjRMPF1gfWLirU8DCMPKqknfDqF9twutKXT186FRn6IyGScz+NIesLEz1HVFWWR\nx5SHYeROJfSEz0YBOZcuI0tkVEK9PnUuNAY2pjwMI08qpSd8EqVScH1No2LkRynCxPOSx5SHYeTO\nQOnYVkoFV2jnQiM/ShUmnivmMDeM/KiUcVMSKUOql0LTqBj5UTEDpoEpD8PIiyx9QCqFkii4mM6F\nGYMbGf1KJQ2YZmYrw8iHSuoJn41i99wuVxqVoUY5xz8JymXX2TByZyB0bCulgutL50IjPyotTNyU\nh2EMMsqh4AoZ3MjIj0oLEzflYRhGQfQ1jYqRP5UUJm4Oc8MwCmUKfUujYuRBhQ2YZsrDMIzCUNXz\nyy3DEKOiwsTNbGUYhjGAqJTxT6zlYRiGMQCotPFPTHkYhmEMDCpmwDQws5VhGIZRAFXlFsAwDMMY\neJjyMAzDMPLGlIdhZEFEvi4iC0Vkvog8LSKHF3Ff94lIc7G2bxj9hTnMDSOAiByJS7dxiKq2icjO\nwPAyi2UYZcdaHoYRphF4XVXbAFT1dVV9RUS+JSJPisgzInKlTxCYajn8TERaRGSxiBwqIjeLyPMi\n8n2/zhQReVZE/uTXuUlE6tN3LCLvEZFHRWSuiNwoIg1++aUissi3hH5SwnNhGN2Y8jCMMHcCk0Tk\nORG5QkTe4ZdfrqqHquo03GBIH4jU2aGqzcBvgFuBs3G9gj8lIjv5dfYFrlDV/YFNwBejO/UtnG8A\n71LVQ4AW4Hxf/yTgQFWdDny/CMdsGFkx5WEYAVR1M65T1lnAa8BfReRTwLEi8riILACOw6UlTzHT\n/y4AFqrqat9yWQZM8mUrVfVhP38d8La0XR8BHAA8LCJPA2cCk3FpKbYDM0TkZGBrvx2sYeSB+TwM\nIwuq2gncB9znlcUXgOlAs6quFJHv4DpwpWjzv12R+dT/1DOX3sEq/b8Ad6nqv6fLIyKHAccDpwBf\nwikvwygp1vIwjAAisq+I7B1ZdDCwxM+/7v0QpxSw6T29Mx7g48BDaeWPAUeLyJu9HCNFZB+/vzF+\nKNLzgIMK2Ldh9BlreRhGmAbglyIyFjf051KcCWsDbvjVNcCTBWx3CXC2iPwBWAT8Olqoqq9589hf\nRCSV+O4buPHCbxWROlzrxDLbGmXB0pMYRokRkSnAbd7ZbhgDEjNbGYZhGHljLQ/DMAwjb6zlYRiG\nYeSNKQ/DMAwjb0x5GIZhGHljysMwDMPIG1MehmEYRt78P1c0GIn3PXC8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a2b7fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write code to access a favorite webpage and extract some text from it. For example, access a weather site and extract the forecast top temperature for your town or city today."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When you have an url, to access the raw material:\n",
    "\n",
    "raw = urllib2.urlopen(url).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Basketball'\n",
    "\n",
    "raw = urllib2.urlopen(url).read().decode('utf8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is important: tokenize the raw material from online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<',\n",
       " u'!',\n",
       " u'DOCTYPE',\n",
       " u'html',\n",
       " u'>',\n",
       " u'<',\n",
       " u'html',\n",
       " u'class=',\n",
       " u\"''\",\n",
       " u'client-nojs']"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, use BeautifulSoup to get the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\n\\n\\nBasketb'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = BeautifulSoup(raw).get_text()\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Basketball',\n",
       " u'-',\n",
       " u'Wikipedia',\n",
       " u'document.documentElement.className',\n",
       " u'=',\n",
       " u'document.documentElement.className.replace',\n",
       " u'(',\n",
       " u'/',\n",
       " u'(',\n",
       " u'^|\\\\s']"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write a function unknown() that takes a URL as its argument, and returns a list of unknown words that occur on that webpage. In order to do this, extract all substrings consisting of lowercase letters (using re.findall()) and remove any items from this set that occur in the Words Corpus (nltk.corpus.words). Try to categorize these words manually and discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'A', u'a', u'aa', u'aal', u'aalii']"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_english = nltk.corpus.words.words('en')\n",
    "word_list_english[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Use .isalpha() to filter words only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Basketball',\n",
       " u'Wikipedia',\n",
       " u'function',\n",
       " u'wgCanonicalNamespace',\n",
       " u'wgCanonicalSpecialPageName',\n",
       " u'false',\n",
       " u'wgNamespaceNumber',\n",
       " u'wgPageName',\n",
       " u'Basketball',\n",
       " u'wgTitle']"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_only_list_web = [word for word in tokens if word.isalpha()]\n",
    "word_only_list_web[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'wikipedia',\n",
       " u'wgcanonicalnamespace',\n",
       " u'wgcanonicalspecialpagename',\n",
       " u'wgnamespacenumber',\n",
       " u'wgpagename',\n",
       " u'wgtitle',\n",
       " u'wgcurrevisionid',\n",
       " u'wgrevisionid',\n",
       " u'wgarticleid',\n",
       " u'wgisarticle']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_not_in_corpus = [word.lower() for word in word_only_list_web \n",
    "                      if word.lower() not in word_list_english]\n",
    "word_not_in_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'players', 66),\n",
       " (u'games', 59),\n",
       " (u'retrieved', 57),\n",
       " (u'women', 54),\n",
       " (u'rules', 53),\n",
       " (u'teams', 51),\n",
       " (u'nba', 50),\n",
       " (u'fiba', 46),\n",
       " (u'played', 44),\n",
       " (u'states', 26),\n",
       " (u'articles', 26),\n",
       " (u'july', 26),\n",
       " (u'american', 24),\n",
       " (u'feet', 24),\n",
       " (u'naismith', 24),\n",
       " (u'has', 23),\n",
       " (u'called', 23),\n",
       " (u'dribbling', 21),\n",
       " (u'leagues', 21),\n",
       " (u'archived', 20)]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(word_not_in_corpus)\n",
    "fd.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most words are in a slightly different form compared with corpus words. e.g. player vs. players, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the result. Sorting result in the nltk.FreqDist as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd_sorted = sorted(fd, key=fd.get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "19."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create a file consisting of words and (made up) frequencies, where each line consists of a word, the space character, and a positive integer, e.g. fuzzy 53. Read the file into a Python list using  open(filename).readlines(). Next, break each line into its two fields using split(), and convert the number into an integer using int(). The result should be a list of the form:  [['fuzzy', 53], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['goose', '1\\n'],\n",
       " ['tampa', '52\\n'],\n",
       " ['astronaut', '109\\n'],\n",
       " ['elephant', '8\\n'],\n",
       " ['naruto', '827\\n'],\n",
       " ['trombone', '3\\n']]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_list = []\n",
    "\n",
    "with open('chap3_ex19.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        freq_list.append(list([line.split(' ')[0], line.split(' ')[1]]))\n",
    "        \n",
    "freq_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The key here is construct a list for each line by list([a, b]). Then insert each small list to the bigger list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\n\\n\\n\\nHome -'"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/\"\n",
    "\n",
    "raw = urllib2.urlopen(url).read().decode('utf8')\n",
    "text = BeautifulSoup(raw).get_text()\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure tokenize text before do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Home', u'-', u'BBC', u'News', u'{', u'``', u'@', u'context', u\"''\", u':']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'H', u'o', u'm', u'e', u'B', u'B', u'C', u'N', u'e', u'w']"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only = [word for word in text if word.isalpha()]\n",
    "text_only[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Home',\n",
       " u'BBC',\n",
       " u'News',\n",
       " u'context',\n",
       " u'http',\n",
       " u'type',\n",
       " u'WebPage',\n",
       " u'url',\n",
       " u'http',\n",
       " u'publisher']"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters_only = [letter for letter in tokens if letter.isalpha()]\n",
    "letters_only[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The key to use regular expression for splitting is to put square brackets and use \"|\" to separate the delimiters/ words that you want to use to split the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pleae ',\n",
       " ' ',\n",
       " 'his ',\n",
       " ' saa ',\n",
       " ' sdasd',\n",
       " ' sdasd ',\n",
       " ' sd shi ^ sdisa, ',\n",
       " '',\n",
       " '',\n",
       " ' a \\n& ',\n",
       " '',\n",
       " '',\n",
       " ' ',\n",
       " ' ',\n",
       " '',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " '',\n",
       " '() use i',\n",
       " ' ',\n",
       " '$',\n",
       " ' sdsa']"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '''pleae ! this * saa * sdasd! sdasd ! sd shi ^ sdisa, not a \n",
    "& not * not not() use it !$* sdsa'''\n",
    "re.split('[!|*|not]',sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pig Latin is a simple transformation of English text. Each word of the text is converted as follows: move any consonant (or consonant cluster) that appears at the start of the word to the end, then append ay, e.g. string → ingstray, idle → idleay.  http://en.wikipedia.org/wiki/Pig_Latin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try to find the first vowel in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vowels = ['a','e','i','o','u']\n",
    "\n",
    "def find_position(word):\n",
    "    for letter in string:\n",
    "        if letter in vowels:\n",
    "            position = string.index(letter)\n",
    "    return position\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now re-construct the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match at 0x11880d5e0>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string='whomwhatever'\n",
    "re.search('[aeiou]',string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'everwhomwhat'"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string='whomwhatever'\n",
    "new_string = string[find_position(string):]+string[:find_position(string)]\n",
    "new_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Python's random module includes a function choice() which randomly chooses an item from a sequence, e.g.  choice(\"aehh \") will produce one of four possible characters, with the letter h being twice as frequent as the others. Write a generator expression that produces a sequence of 500 randomly chosen letters drawn from the string \"aehh \", and put this expression inside a call to the ''.join() function, to concatenate them into one long string. You should get a result that looks like uncontrolled sneezing or maniacal laughter: he  haha ee  heheeh eha. Use split() and join() again to normalize the whitespace in this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice('aeiou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do something N times, use the itertools. The details are in my personal Github page:\n",
    "https://github.com/thatMeow/My_Python_Skills_Collections/blob/master/Miscellaneous/Iterations/do_something_n_times.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ahhahaehhaaaeahhhaeehheehhhaaaheahhhahahahhahhehahhhaaheaeehaaaeaehhhaehaheaheehahheheeheahhehaehhhahhhheaeaheehahhhhheaaahheeheehhahaaehhaehhhaeaaaheaeeaaahhehhhaahaaehhhaaaeehaeeahheehhhhhaaaehhehhhaehhaaaaeaheaahehhheahehhhaaahehaaeaheheahhaeeaeheehehaaaheaehhahheeaaaeheehhehhehheeheaahehehahahhhehhhahhhehhehhhhahahaahheheehhhaeeeehhhhahhheaeaeehhhhhhaehhhahehheheehehhaaehhaeheaehhhehaeeeahhhahhhhahhhhhhhhahahhhhhahahehahahhaheahehhhehahheehhhhhaeahhhhhheaehhehheaaehhhaeaaeehaeaheehhhhehaheee'"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "string = 'aehh'\n",
    "\n",
    "list_=[]\n",
    "\n",
    "for _ in itertools.repeat(None, 500):\n",
    "    list_.append(random.choice(string))\n",
    "    \n",
    "    \n",
    "result = ''.join(list_)\n",
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use .count('x') to count the number of character in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of letter a is: 130\n",
      "Number of letter e is: 128\n",
      "Number of letter h is: 242\n"
     ]
    }
   ],
   "source": [
    "for letter in 'aeh':\n",
    "    print \"Number of letter \"+ letter + \" is: \" + str(result.count(letter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Readability measures are used to score the reading difficulty of a text, for the purposes of selecting texts of appropriate difficulty for language learners. Let us define μw to be the average number of letters per word, and μs to be the average number of words per sentence, in a given text. The Automated Readability Index (ARI) of the text is defined to be: 4.71 μw + 0.5 μs - 21.43. Compute the ARI score for various sections of the Brown Corpus, including section f (lore) and j (learned). Make use of the fact that nltk.corpus.brown.words() produces a sequence of words, while nltk.corpus.brown.sents() produces a sequence of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the brown corpus in nltk first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My personal Github page of nltk book, chapter 2, contains the syntax to import nltk corpus and check files, get words, etc.:\n",
    "https://github.com/thatMeow/Natural-Language-Processing/blob/master/NLTK_Book/2%20-%20Accessing%20Text%20Corpora%20and%20Lexical%20Resources.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ca01', u'ca02', u'ca03', u'ca04', u'ca05']"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.fileids()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr07 2456\n",
      "cr08 2371\n",
      "cr09 2332\n"
     ]
    }
   ],
   "source": [
    "for file_ in brown.fileids()[-3:]:\n",
    "    print file_, len(brown.words(file_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first file and see the words in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'The', u'Fulton', u'County', u'Grand', u'Jury', ...]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_words = brown.words('ca01')\n",
    "sample_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of chapters, sentences, and words in the last 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name:  cr07\n",
      "Number of raw content:  19973\n",
      "Number of sentences:  184\n",
      "Number of words:  2456\n",
      "Number of unique words:  724\n",
      "\n",
      "\n",
      "File name:  cr08\n",
      "Number of raw content:  20608\n",
      "Number of sentences:  70\n",
      "Number of words:  2371\n",
      "Number of unique words:  1067\n",
      "\n",
      "\n",
      "File name:  cr09\n",
      "Number of raw content:  19645\n",
      "Number of sentences:  99\n",
      "Number of words:  2332\n",
      "Number of unique words:  1072\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_ in brown.fileids()[-3:]:\n",
    "    print \"File name: \", file_\n",
    "    print \"Number of raw content: \", len(brown.raw(file_))\n",
    "    print \"Number of sentences: \", len(brown.sents(file_))\n",
    "    print \"Number of words: \", len(brown.words(file_))\n",
    "    print \"Number of unique words: \", len(set(brown.words(file_)))\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name:  cr07\n",
      "Number of characters per word:  8\n",
      "Number of words per sentence:  13\n",
      "ARI for file cr07 is:  29.25\n",
      "\n",
      "\n",
      "File name:  cr08\n",
      "Number of characters per word:  8\n",
      "Number of words per sentence:  33\n",
      "ARI for file cr08 is:  49.25\n",
      "\n",
      "\n",
      "File name:  cr09\n",
      "Number of characters per word:  8\n",
      "Number of words per sentence:  23\n",
      "ARI for file cr09 is:  39.25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_ in brown.fileids()[-3:]:\n",
    "    print \"File name: \", file_\n",
    "    print \"Number of characters per word: \", len(brown.raw(file_))/len(brown.words(file_))\n",
    "    print \"Number of words per sentence: \", len(brown.words(file_))/len(brown.sents(file_))\n",
    "    print \"ARI for file \" + file_ + \" is: \", 4.71*(len(brown.raw(file_))/len(brown.words(file_)))+(len(brown.words(file_))/len(brown.sents(file_)))-21.43\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use the Porter Stemmer to normalize some tokenized text, calling the stemmer on each word. Do the same thing with the Lancaster Stemmer and see if you observe any differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porter and Lancaster Stemmer can be found in my personal Github page:\n",
    "https://github.com/thatMeow/Natural-Language-Processing/blob/master/NLTK_Book/3%20-%20Processing%20Raw%20Text%20-%20Part%202.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's get the Porter and Lancaster Stemmers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a sentence and tokenize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = '''\n",
    "        Writing some words that can use stemmers: lying on the ground \n",
    "        and counting stars. Men and women, American or Chinese.\n",
    "        '''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply stemmers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'write',\n",
       " 'some',\n",
       " u'word',\n",
       " 'that',\n",
       " 'can',\n",
       " 'use',\n",
       " u'stemmer',\n",
       " ':',\n",
       " u'lie',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'and',\n",
       " u'count',\n",
       " u'star',\n",
       " '.',\n",
       " 'men',\n",
       " 'and',\n",
       " 'women',\n",
       " ',',\n",
       " 'american',\n",
       " 'or',\n",
       " u'chines',\n",
       " '.']"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writ',\n",
       " 'som',\n",
       " 'word',\n",
       " 'that',\n",
       " 'can',\n",
       " 'us',\n",
       " 'stem',\n",
       " ':',\n",
       " 'lying',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'and',\n",
       " 'count',\n",
       " 'star',\n",
       " '.',\n",
       " 'men',\n",
       " 'and',\n",
       " 'wom',\n",
       " ',',\n",
       " 'am',\n",
       " 'or',\n",
       " 'chines',\n",
       " '.']"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lancaster.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Define the variable saying to contain the list ['After', 'all', 'is', 'said', 'and', 'done', ',', 'more',\n",
    "'is', 'said', 'than', 'done', '.']. Process this list using a for loop, and store the length of each word in a new list lengths. Hint: begin by assigning the empty list to lengths, using lengths = []. Then each time through the loop, use append() to add another length value to the list. Now do the same thing using a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 4, 3, 4, 1, 4, 2, 4, 4, 4, 1]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['After', 'all', 'is', 'said', 'and', 'done', ',', 'more',\n",
    "'is', 'said', 'than', 'done', '.']\n",
    "\n",
    "length_list = []\n",
    "\n",
    "for word in word_list:\n",
    "    length_list.append(len(word))\n",
    "length_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 4, 3, 4, 1, 4, 2, 4, 4, 4, 1]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list = []\n",
    "\n",
    "[length_list.append(len(word)) for word in word_list]\n",
    "length_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Define a variable silly to contain the string: 'newly formed bland ideas are inexpressible in an infuriating\n",
    "way'. (This happens to be the legitimate interpretation that bilingual English-Spanish speakers can assign to Chomsky's famous nonsense phrase, colorless green ideas sleep furiously according to Wikipedia). Now write code to perform the following tasks:\n",
    "\n",
    "a. Split silly into a list of strings, one per word, using Python's split() operation, and save this to a variable called  bland.\n",
    "b. Extract the second letter of each word in silly and join them into a string, to get 'eoldrnnnna'.\n",
    "c. Combine the words in bland back into a single string, using join(). Make sure the words in the resulting string are separated with whitespace.\n",
    "d. Print the words of silly in alphabetical order, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "silly = 'newly formed bland ideas are inexpressible in an infuriating way'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Split silly into a list of strings, one per word, using Python's split() operation, and save this to a variable called  bland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['newly',\n",
       " 'formed',\n",
       " 'bland',\n",
       " 'ideas',\n",
       " 'are',\n",
       " 'inexpressible',\n",
       " 'in',\n",
       " 'an',\n",
       " 'infuriating',\n",
       " 'way']"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bland = silly.split()\n",
    "bland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Extract the second letter of each word in silly and join them into a string, to get 'eoldrnnnna'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eoldrnnnna'"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_letter = ''\n",
    "for word in bland:\n",
    "    second_letter += word[1]\n",
    "second_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Combine the words in bland back into a single string, using join(). Make sure the words in the resulting string are separated with whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newly formed bland ideas are inexpressible in an infuriating way'"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_bland = ' '.join(bland)\n",
    "new_bland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!d. Print the words of silly in alphabetical order, one per line."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use 'find' method to locate the letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'abcdefg'\n",
    "string.find('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newly 13 4\n",
      "formed 5 14\n",
      "bland 1 11\n",
      "ideas 8 3\n",
      "are 0 17\n",
      "inexpressible 8 13\n",
      "in 8 13\n",
      "an 0 13\n",
      "infuriating 8 13\n",
      "way 22 0\n"
     ]
    }
   ],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "for word in bland:\n",
    "    print word, alphabet.find(word[0]), alphabet.find(word[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "An easier way is to use sorted() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'are',\n",
       " 'bland',\n",
       " 'formed',\n",
       " 'ideas',\n",
       " 'in',\n",
       " 'inexpressible',\n",
       " 'infuriating',\n",
       " 'newly',\n",
       " 'way']"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bland)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The index() function can be used to look up items in sequences. For example, 'inexpressible'.index('e') tells us the index of the first position of the letter e.\n",
    "\n",
    "a. What happens when you look up a substring, e.g. 'inexpressible'.index('re')?\n",
    "b. Define a variable words containing a list of words. Now use words.index() to look up the position of an individual word.\n",
    "c. Define a variable silly as in the exercise above. Use the index() function in combination with list slicing to build a list phrase consisting of all the words up to (but not including) in in silly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'inexpressible'\n",
    "string.index('ress')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "index() function only return the index of 1st letter of the characters that you need to look up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['word', 'sun', 'bliss', 'samual', 'forest']\n",
    "words.index('bliss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34.!!! This is hard coded question, leave for now unless automated way is found"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write code to convert nationality adjectives like Canadian and Australian to their corresponding nouns Canada and Australia (see http://en.wikipedia.org/wiki/List_of_adjectival_forms_of_place_names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try one word using stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canadian'"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('Canadian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Oh', u'hai', u'.', u'In', u'teh']"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.corpus.genesis.words('lolcat.txt')\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "37."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Read about the re.sub() function for string substitution using regular expressions, using help(re.sub) and by consulting the further readings for this chapter. Use re.sub in writing code to remove HTML tags from an HTML file, and to normalize whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thzzzzz zzzzz whzzzzz things go well'"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"This is where things go well\"\n",
    "re.sub('is|ere','zzzzz',sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = \"https://en.wikipedia.org/wiki/Natural_language\"\n",
    "raw = urllib2.urlopen(link).read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<', u'!', u'DOCTYPE', u'html', u'>']"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({wgCanonicalNamespace:,wgCanonicalSpecialPageName:false,wgNamespaceNumber:0,wgPageName:Natural_language,wgTitle:Natural language,wgCurRevisionId:769673929,wgRevisionId:769673929,wgArticleId:21173,wgIsArticle:true,wgIsRedirect:false,wgAction:view,wgUserName:null,wgUserGroups:[*],wgCategories:[Use dmy dates from July 2012,Natural language processing,Neuropsychological assessment,Language,Philosophical logic,Philosophy of language],wgBreakFrames:false,wgPageContentLanguage:en,wgPageContentModel:wikitext,wgSeparatorTransformTable:[,],wgDigitTransformTable:[,],wgDefaultDateFormat:dmy,wgMonthNames:[,January,February,March,April,May,June,July,August,September,October,November,December],wgMonthNamesShort:[,Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec],wgRelevantPageName:Natural_language,wgRelevantArticleId:21173,wgRequestId:WRZL-ApAMFwAAHeLHZ0AAAAB,wgIsProbablyEditable:true,wgRestrictionEdit:[],wgRestrictionMove:[],wgFlaggedRevsParams:{tags:{}},wgStableRevisionId:null,wgWikiEditorEnabledModules:{toolbar:true,dialogs:true,preview:false,publish:false},wgBetaFeaturesFeatures:[],wgMediaViewerOnClick:true,wgMediaViewerEnabledByDefault:false,wgPopupsShouldSendModuleToUser:false,wgPopupsConflictsWithNavPopupGadget:false,wgVisualEditor:{pageLanguageCode:en,pageLanguageDir:ltr,usePageImages:true,usePageDescriptions:true},wgPreferredVariant:en,wgMFDisplayWikibaseDescriptions:{search:true,nearby:true,watchlist:true,tagline:false},wgRelatedArticles:null,wgRelatedArticlesUseCirrusSearch:true,wgRelatedArticlesOnlyUseCirrusSearch:false,wgULSCurrentAutonym:English,wgNoticeProject:wikipedia,wgCentralNoticeCookiesToDelete:[],wgCentralNoticeCategoriesUsingLegacy:[Fundraising,fundraising],wgCategoryTreePageCategoryOptions:{mode:0,hideprefix:20,showcount:true,namespaces:false},wgWikibaseItemId:Q33742,wgCentralAuthMobileDomain:false,wgVisualEditorToolbarScrollOffset:0,wgVisualEditorUnsupportedEditParams:[preload,preloadparams,preloadtitle,undo,undoafter,veswitched],wgEditSubmitButtonLabelPublish:false});mw.loader.state({ext.globalCssJs.user.styles:ready,ext.globalCssJs.site.styles:ready,site.styles:ready,noscript:ready,user.styles:ready,user:ready,user.options:loading,user.tokens:loading,ext.cite.styles:ready,wikibase.client.init:ready,ext.visualEditor.desktopArticleTarget.noscript:ready,ext.uls.interlanguage:ready,ext.wikimediaBadges:ready,mediawiki.legacy.shared:ready,mediawiki.legacy.commonPrint:ready,mediawiki.sectionAnchor:ready,mediawiki.skinning.interface:ready,skins.vector.styles:ready,ext.globalCssJs.user:ready,ext.globalCssJs.site:ready});mw.loader.implement(user.options@0j3lz3q,function($,jQuery,require,module){mw.user.options.set({variant:en});});mw.loader.implement(user.tokens@1dqfd7l,function ( $, jQuery, require, module ) {mw.user.tokens.set({editToken:+,patrolToken:+,watchToken:+,csrfToken:+});/*@nomin*/;});mw.loader.load([ext.cite.a11y,mediawiki.toc,site,mediawiki.page.startup,mediawiki.user,mediawiki.hidpi,mediawiki.page.ready,mediawiki.searchSuggest,ext.gadget.teahouse,ext.gadget.ReferenceTooltips,ext.gadget.watchlist-notice,ext.gadget.DRN-wizard,ext.gadget.charinsert,ext.gadget.refToolbar,ext.gadget.extra-toolbar-buttons,ext.gadget.switcher,ext.gadget.featured-articles-links,ext.centralauth.centralautologin,ext.visualEditor.desktopArticleTarget.init,ext.visualEditor.targetLoader,ext.eventLogging.subscriber,ext.wikimediaEvents,ext.navigationTiming,ext.uls.eventlogger,ext.uls.init,ext.uls.interface,ext.quicksurveys.init,ext.centralNotice.geoIP,ext.centralNotice.startUp,skins.vector.js]);});Jump to:<!-- NewPP limit reportParsed by mw1257Cached time: 20170512235748Cache expiry: 2592000Dynamic content: falseCPU time usage: 0.100 secondsReal time usage: 0.142 secondsPreprocessor visited node count: 515/1000000Preprocessor generated node count: 0/1500000Post\\u2010expand include size: 18503/2097152 bytesTemplate argument size: 400/2097152 bytesHighest expansion depth: 12/40Expensive parser function count: 1/500Lua time usage: 0.038/10.000 secondsLua memory usage: 1.81 MB/50 MB--><!--Transclusion expansion time report (%,ms,calls,template)100.00%  114.594      1 -total 44.70%   51.228      1 Template:Reflist 37.94%   43.472      2 Template:Cite_book 16.97%   19.441      1 Template:Neuropsychology 15.39%   17.633      1 Template:About 15.03%   17.224      1 Template:Sidebar_with_collapsible_lists 10.91%   12.500      1 Template:Use_dmy_dates  6.84%    7.837      1 Template:DMCA  5.86%    6.720      1 Template:Dated_maintenance_category  4.30%    4.929      2 Template:Main--><!-- Saved in parser cache with key enwiki:pcache:idhash:21173-0!*!0!!en!*!* and timestamp 20170512235748 and revision id 769673929 -->Retrieved from ;additional terms may apply.  By using this site, you agree to the '"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<.*>|\\n|\\t|\"|\\\\\\\\','',raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "An interesting challenge for tokenization is words that have been split across a line-break. E.g. if long-term is split, then we have the string long-\\nterm.\n",
    "\n",
    "1. Write a regular expression that identifies words that are hyphenated at a line-break. The expression will need to include the \\n character.\n",
    "2. Use re.sub() to remove the \\n character from these words.\n",
    "3. How might you identify words that should not remain hyphenated once the newline is removed, e.g.  'encyclo-\\npedia'?x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"bla bla bla infor-\n",
    "... mation bla bla bla\"\"\"\n",
    "[word for word in sent if re.search('-\\n', word)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-\\nb-\\nl-\\na-\\n -\\nb-\\nl-\\na-\\n -\\nb-\\nl-\\na-\\n -\\ni-\\nn-\\nf-\\no-\\nr-\\n--\\n\\n-\\nm-\\na-\\nt-\\ni-\\no-\\nn-\\n -\\nb-\\nl-\\na-\\n -\\nb-\\nl-\\na-\\n -\\nb-\\nl-\\na-\\n'"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('','-\\n', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Read the Wikipedia entry on Soundex. Implement this algorithm in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Soundex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules of Soundex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Retain the first letter of the name and drop all other occurrences of a, e, i, o, u, y, h, w.\n",
    "\n",
    "2. Replace consonants with digits as follows (after the first letter):\n",
    "b, f, p, v → 1\n",
    "c, g, j, k, q, s, x, z → 2\n",
    "d, t → 3\n",
    "l → 4\n",
    "m, n → 5\n",
    "r → 6\n",
    "\n",
    "3. If two or more letters with the same number are adjacent in the original name (before step 1), only retain the first letter; also two letters with the same number separated by 'h' or 'w' are coded as a single number, whereas such letters separated by a vowel are coded twice. This rule also applies to the first letter.\n",
    "\n",
    "4. If you have too few letters in your word that you can't assign three numbers, append with zeros until there are three numbers. If you have more than 3 letters, just retain the first 3 numbers."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using this algorithm, both \"Robert\" and \"Rupert\" return the same string \"R163\" while \"Rubin\" yields \"R150\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j25'"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'jasonnon'\n",
    "\n",
    "def soundex(word):\n",
    "    soundex_word = word[0]\n",
    "    word = re.sub('[aeiouyhw]','',word[1:]) # use regex's sub() method to replace letters\n",
    "    \n",
    "    def consonants_digit(letter):\n",
    "        if letter in 'bfpv':\n",
    "            return 1\n",
    "        elif letter in 'cgjkqsxz':\n",
    "            return 2\n",
    "        elif letter in 'dt':\n",
    "            return 3\n",
    "        elif letter == 'l':\n",
    "            return 4\n",
    "        elif letter in 'mn':\n",
    "            return 5\n",
    "        else:\n",
    "            return 6\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        soundex_word = soundex_word + str(consonants_digit(word[i]))\n",
    "    # so far step 1 and step 2 are done, for step 3:\n",
    "    def drop_step_3(word):\n",
    "        for i in range(len(word)-1):\n",
    "            if word[i] == word[i+1]:\n",
    "                word = word.replace(word[i],'z', 1)\n",
    "        word = re.sub('z','',word)\n",
    "        return word\n",
    "\n",
    "    return drop_step_3(soundex_word) \n",
    "        \n",
    "soundex(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rewrite the following nested loop as a nested list comprehension"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    ">>> result = []\n",
    ">>> for word in sent:\n",
    "...     word_len = (word, len(word))\n",
    "...     result.append(word_len)\n",
    ">>> result\n",
    "[('The', 3), ('dog', 3), ('gave', 4), ('John', 4), ('the', 3), ('newspaper', 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "[(word, len(word)) for word in word_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first time I worked on this I got stuck"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rewrite the following nested loop as a nested list comprehension"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> words = ['attribution', 'confabulation', 'elocution',\n",
    "...          'sequoia', 'tenacious', 'unidirectional']\n",
    ">>> vsequences = set()\n",
    ">>> for word in words:\n",
    "...     vowels = []\n",
    "...     for char in word:\n",
    "...         if char in 'aeiou':\n",
    "...             vowels.append(char)\n",
    "...     vsequences.add(''.join(vowels))\n",
    ">>> sorted(vsequences)\n",
    "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An answer from stack overflow:\n",
    "\n",
    "http://stackoverflow.com/questions/43964923/python-nested-list-comprehension-in-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['attribution', 'confabulation', 'elocution', 'sequoia', 'tenacious', 'unidirectional']\n",
    "\n",
    "sorted(set([\"\".join([char for char in word if char in 'aeiou']) for word in words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The key here is put the \"if\" condition with the char loop, then do the word loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
