{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist # need this to access \"most_common\" method\n",
    "\n",
    "import urllib2\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import re\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from __future__  import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penn POS Tags:\n",
    "\n",
    "https://cs.nyu.edu/grishman/jet/guide/PennPOS.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ☼ Search the web for \"spoof newspaper headlines\", to find such gems as: British Left Waffles on Falkland Islands, and Juvenile Court to Try Shooting Defendant. Manually tag these headlines to see if knowledge of the part-of-speech tags removes the ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('British', 'JJ'),\n",
       " ('Left', 'NNP'),\n",
       " ('Waffles', 'NNP'),\n",
       " ('on', 'IN'),\n",
       " ('Falkland', 'NNP'),\n",
       " ('Islands', 'NNP')]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"British Left Waffles on Falkland Islands\"\n",
    "tokens1 = nltk.word_tokenize(sent1)\n",
    "nltk.pos_tag(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Juvenile', 'NNP'),\n",
       " ('Court', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('Try', 'VB'),\n",
       " ('Shooting', 'NNP'),\n",
       " ('Defendant', 'NNP')]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2 = \"Juvenile Court to Try Shooting Defendant\"\n",
    "tokens2 = nltk.word_tokenize(sent2)\n",
    "nltk.pos_tag(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The POS tagging did NOT remove the ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ☼ Tokenize and tag the following sentence: They wind back the clock, while we chase after the wind. What different pronunciations and parts of speech are involved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('wind', 'VBP'),\n",
       " ('back', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('clock', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('chase', 'VBP'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('wind', 'NN')]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"They wind back the clock, while we chase after the wind\"\n",
    "tokens = nltk.word_tokenize(sent)\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different part of speech: PRP, VBP, RB, DT, NN, IN."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PRP: Personal Pronoun\n",
    "VBP: Verb, non-3rd person singular present\n",
    "RB : Adverb\n",
    "DT : Determiner\n",
    "NN : Noun, singular or mass\n",
    "IN : Preposition or subordinating conjunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. ☼ Using the Python interpreter in interactive mode, experiment with the dictionary examples in this chapter. Create a dictionary d, and add some entries. What happens if you try to access a non-existent entry, e.g. d['xyz']?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = dict()# or {}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1['a'] = 1\n",
    "dict1['b'] = 2\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dict1['xyz']\n",
    "except KeyError:\n",
    "    print \"Key not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do default dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 1, 'b': 2})"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dict2 = defaultdict(int)\n",
    "dict2['a'] = 1\n",
    "dict2['b'] = 2\n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print dict2['xyz']\n",
    "except KeyError:\n",
    "    print \"Key not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. ☼ Try deleting an element from a dictionary d, using the syntax del d['abc']. Check that the item was deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dict1['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 2}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see how to delete element from dict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. ☼ Create two dictionaries, d1 and d2, and add some entries to each. Now issue the command d1.update(d2). What did this do? What might it be useful for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1, 2, 3], 'b': 'interesting', 'c': {'vvv': 2, 'zzz': 1}}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {'a':[1,2,3], 'b':'interesting', 'c':{'zzz':1, 'vvv':2}}\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2 = {'ggg':2, 'that':'this'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1, 2, 3],\n",
       " 'b': 'interesting',\n",
       " 'c': {'vvv': 2, 'zzz': 1},\n",
       " 'ggg': 2,\n",
       " 'that': 'this'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.update(d2)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ggg': 2, 'that': 'this'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"d1.update(variable)\" is used to add element to dictionaries. Here we update d1 using d2 basically add all element from d2 to d1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. ☼ Train a unigram tagger and run it on some new text. Observe that some words are not assigned a tag. Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = len(nltk.corpus.brown.tagged_sents())\n",
    "train_size = int(length*0.8)\n",
    "test_size = int(length*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45872"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure use \"int()\" to make it integers. \n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'The', u'AT'),\n",
       " (u'Fulton', u'NP-TL'),\n",
       " (u'County', u'NN-TL'),\n",
       " (u'Grand', u'JJ-TL'),\n",
       " (u'Jury', u'NN-TL'),\n",
       " (u'said', u'VBD'),\n",
       " (u'Friday', u'NR'),\n",
       " (u'an', u'AT'),\n",
       " (u'investigation', u'NN'),\n",
       " (u'of', u'IN'),\n",
       " (u\"Atlanta's\", u'NP$'),\n",
       " (u'recent', u'JJ'),\n",
       " (u'primary', u'NN'),\n",
       " (u'election', u'NN'),\n",
       " (u'produced', u'VBD'),\n",
       " (u'``', u'``'),\n",
       " (u'no', u'AT'),\n",
       " (u'evidence', u'NN'),\n",
       " (u\"''\", u\"''\"),\n",
       " (u'that', u'CS'),\n",
       " (u'any', u'DTI'),\n",
       " (u'irregularities', u'NNS'),\n",
       " (u'took', u'VBD'),\n",
       " (u'place', u'NN'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_sents = nltk.corpus.brown.tagged_sents()[:train_size]\n",
    "test_set_sents = nltk.corpus.brown.tagged_sents()[train_size:]\n",
    "\n",
    "\n",
    "training_set_sents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UnigramTagger: size=51461>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train unigram taggers\n",
    "unigram_tagger = nltk.UnigramTagger(training_set_sents)\n",
    "unigram_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'The', u'AT'),\n",
       " (u'September-October', u'NP'),\n",
       " (u'term', u'NN'),\n",
       " (u'jury', u'NN'),\n",
       " (u'had', u'HVD'),\n",
       " (u'been', u'BEN'),\n",
       " (u'charged', u'VBN'),\n",
       " (u'by', u'IN'),\n",
       " (u'Fulton', u'NP-TL'),\n",
       " (u'Superior', u'JJ-TL'),\n",
       " (u'Court', u'NN-TL'),\n",
       " (u'Judge', u'NN-TL'),\n",
       " (u'Durwood', u'NP'),\n",
       " (u'Pye', u'NP'),\n",
       " (u'to', u'TO'),\n",
       " (u'investigate', u'VB'),\n",
       " (u'reports', u'NNS'),\n",
       " (u'of', u'IN'),\n",
       " (u'possible', u'JJ'),\n",
       " (u'``', u'``'),\n",
       " (u'irregularities', u'NNS'),\n",
       " (u\"''\", u\"''\"),\n",
       " (u'in', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'hard-fought', u'JJ'),\n",
       " (u'primary', u'JJ'),\n",
       " (u'which', u'WDT'),\n",
       " (u'was', u'BEDZ'),\n",
       " (u'won', u'VBD'),\n",
       " (u'by', u'IN'),\n",
       " (u'Mayor-nominate', u'NN-TL'),\n",
       " (u'Ivan', u'NP'),\n",
       " (u'Allen', u'NP'),\n",
       " (u'Jr.', u'NP'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use trained unigram taggers to tag sentence\n",
    "\n",
    "unigram_tagger.tag(nltk.corpus.brown.sents()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771110352197239"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at accuracy score\n",
    "unigram_tagger.evaluate(test_set_sents)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "\n",
    "1. Get the tagged sents\n",
    "2. Training the unigram tagger: nltk.UnigramTagger(tagged_sents)\n",
    "3. Tag the article: tagger.tag(sent_to_be_tagged)\n",
    "4. Accuracy score: tagger.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's combine multiple taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071034338404592"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(training_set_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(training_set_sents, backoff=t1)\n",
    "t2.evaluate(test_set_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see combining different taggers together will improve accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we add trigram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009727562160554"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(training_set_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(training_set_sents, backoff=t1)\n",
    "t3 = nltk.TrigramTagger(training_set_sents, backoff=t1)\n",
    "t3.evaluate(test_set_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case trigram perform the same as bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
